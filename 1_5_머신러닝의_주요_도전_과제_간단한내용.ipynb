{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.5 머신러닝의 주요 도전 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4jckj4pk/CYn8qjts4pwu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pITksnUiP8GT"
      },
      "source": [
        "**1. 충분하지 않은 양의 훈련데이터**\n",
        "- 간단한 문제라도 수천 개의 데이터가 필요함\n",
        "- 이미지나 음성 인식 같은 문제는 수백만갤 필요로 할 수 있음\n",
        "- 데이터가 부족하면 알고리즘을 개선하기 위한 노력이 헛수고일 가능성이 있음\n",
        "- 반대로 데이터가 충분하다면 알고리즘의 성능을 크게 높일 수 있음\n",
        "- 이런 패러다임이 딥러닝 발전의 원동력\n",
        "\n",
        "**2. 대표성이 없는 훈련 데이터**\n",
        "- 모델이 일반화가 잘되려면 예측하려는 샘플의 분포를 잘 따르는 훈련 샘플을 만들어야 함\n",
        "- 만약 우연에 의해 대표성이 없는 데이터가 만들어졌다면 이를 샘플링 잡음이라고 함\n",
        "- 혹은 샘플 추출 방법이 잘못되어 대표성이 없는 데이터는 샘플링 편항이라고 함\n",
        "\n",
        "**3. 낮은 품질의 데이터**\n",
        "- 훈련 데이터에 이상치나 잡음이 많으면 올바른 모델을 만들기 어려울 것임\n",
        "- 이러한 이유때문에 데이터를 정제하는데에 많은 노력을 기울임\n",
        "- 만약 이상치 샘플이라면 고치거나 무시함\n",
        "- 특성이 누락되었을 때,\n",
        "\n",
        "  ㄱ. 해당 특성을 제외\n",
        "\n",
        "  ㄴ. 해당 샘플을 제외\n",
        "\n",
        "  ㄷ. 누락된 값을 채움\n",
        "\n",
        "  ㄹ. 해당 특성을 넣은 경우와 뺀 경우 각기 모델을 훈련\n",
        "\n",
        "**4. 관련 없는 특성 **\n",
        "- 좋은 모델을 만들기 위해서는 문제와 관련이 높은 특성을 찾아야 함\n",
        "- 이런 좋은 특성을 찾는 것을 '특성 공학(Feature Engineering)'이라고 부름\n",
        "- 특성 선택 방법과 특성 추출 방법이 있음\n",
        " ㄱ. 특성 선택 : 준비되어 있는 특성 중 가장 유용한 특성을 찾음\n",
        " ㄴ. 특성 추출 : 특성을 조합하여 새로운 특성을 만듬\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKn3HsZQR1-f"
      },
      "source": [
        "**5. 과대 적합**\n",
        "- 훈련 세트와 너무 잘 맞는 모델은 일반화 성능이 낮을 수 있는데 이러한 현상을 과대적합이라고 함\n",
        " 예) 모든 훈련 데이터를 지나가는 구불구불한 선을 그릴 수 있음\n",
        "- 이런 복잡한 모델을 단순화하여 일반화 성능을 높이기 위해 사용하는 방법 중 하나를 '규제'라고 함\n",
        "- 규제는 모델 파라미터에 제약을 가하여 이 모델이 조금 더 거시적/일반적 패턴을 따르도록 만드는 방법임 \n",
        "\n",
        "**6. 과소 적합**\n",
        "- 과대 적합의 반대\n",
        "- 모델이 너무 단순하여 훈련 세트를 제대로 학습하지 못할 때 일어나는 현상\n",
        "- 과소적합을 해결하기 위해서는 과대 적합의 반대로 하면 됨\n",
        "\n",
        " ㄱ. 모델 파라미터가 더 많은 모델을 사용\n",
        "\n",
        " ㄴ. 특성 공학으로 더 좋은 특성을 찾음\n",
        "\n",
        " ㄷ. 규제의 강도를 줄여 훈련 세트에 조금 과대적합하도록 유도하는 방법\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zWowzaRTX14"
      },
      "source": [
        "**7. 테스트 세트와 검증 세트**\n",
        "- 일반화 성능을 테스트하기 위해서 테스트와 검증 세트로 나눔\n",
        "- 훈련 세트로 모델을 학습시키고 데스트 세트로 모델을 평가하여 모델의 일반화 성능을 측정함\n",
        "- 위에서 말한 것과 같이 규제로 조정하는 것들을 하이퍼파라미터라고 부름 (모델이 조정하는 파라미터가 아니라 알고리즘을 조절하기 위해 사전에 정의하는 파라미터로 좋은 파라미터를 찾기위해서 다양하게 시도해볼 수 있음)\n",
        "- 그런데 테스트 세트를 사용해 여러 모델을 평가하면 테스트 세트에 과대적합될 수 있음\n",
        "- 실전에 투입해서 좋은 성능을 낼 수 있도록 하기 위해서는 훈련세트, 검증세트, 테스트 세트로 나누는 것이 좋음.\n",
        "- 훈련 세트를 한번 더 나누어 검증 세트를 만들어 훈련 세트로 모델을 훈련하고 검증세트에서 파라미터를 고르고 마지막으로 최종 모델을 고르고, 테스트 세트로 일반화 성능을 검증\n",
        "\n",
        "**훈련 - 개발 세트**\n",
        "- 대량의 데이터를 손쉽게 얻기 위해 실전과 다른 데이터로 훈련 세트를 만들수도 있음\n",
        " \n",
        " 예) 아주 희귀한 꽃 이미지 분류기\n",
        "\n",
        "- 이렇게 만들어진 훈련 세트는 양이 많아져서 풍부한 훈련 세트를 제공해줄 수 있지만 실제 데이터와는 다르기 때문에 일반화 성능을 올바르게 평가하려면 검증 세트에 진짜 데이터를 섞어주어야 함. \n",
        "- 이런 경우에 검증 세트 점수가 과대적합인 것인지 아니면 데이터 불일치로 인해 일어난 것인지 알 수 없음\n",
        "- 이를 위해서 훈련-개발 세트라는 것을 하나 더 만듬\n",
        " ㄱ. 훈련 세트에서 모델을 훈련\n",
        " ㄴ. 훈련 세트에서 만들어진 훈련-개발 세트에서 모델을 평가\n",
        " ㄷ. 만약에 훈련 개발 세트 성능이 낮다면 과대적합\n",
        " ㄹ. 검증 세트 성능이 낮다면 데이터 불일치\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBjBq3AoVbW5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}